{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import datetime\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input data from User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Market analysed: 'Investment','FullYear','DayAhead','Balancing' (choose one or several)\n",
    "markets=['DayAhead'] \n",
    "output='PriceElectricityHourly'\n",
    "first_timestep=\"2012-01-02\"\n",
    "#Meaning of SSS and TTT in the data: 'DaysHours','Hours5min','WeeksHours'\n",
    "meaning_SSS_TTT='DaysHours'\n",
    "#Time size of each time step in TTT for creating timestamp\n",
    "size_timestep=\"3600s\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set plotting specifications\n",
    "%matplotlib inline\n",
    "plt.rcParams.update({'font.size': 21})\n",
    "plt.rcParams['xtick.major.pad']='12'\n",
    "plt.rc('legend', fontsize=16)\n",
    "y_limit = 1.1\n",
    "lw = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Input Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.DataFrame()\n",
    "for market in markets:\n",
    "    csvfiles = []\n",
    "    for file in glob.glob(\"./input/results/\" + market + \"/*.csv\"):\n",
    "        csvfiles.append(file)\n",
    "\n",
    "    csvfiles=[file.replace('./input\\\\','') for file in csvfiles] \n",
    "    csvfiles=[file.replace('.csv','') for file in csvfiles]  \n",
    "    csvfiles=[file.split('_') for file in csvfiles]  \n",
    "    csvfiles = np.asarray(csvfiles)  \n",
    "    csvfiles=pd.DataFrame.from_records(csvfiles)\n",
    "    \n",
    "    csvfiles.rename(columns={0: 'Output', 1: 'Scenario',2: 'Year',3:'Subset'}, inplace=True)\n",
    "    scenarios=csvfiles.Scenario.unique().tolist()\n",
    "    years=csvfiles.Year.unique().tolist()\n",
    "    subsets=csvfiles.Subset.unique().tolist()\n",
    "\n",
    "    for scenario in scenarios:\n",
    "        for year in years:\n",
    "            for subset in subsets:\n",
    "                file = \"./input/results/\"+ market + \"/\"+ output + \"_\" + scenario + \"_\" + year + \"_\" + subset + \".csv\"\n",
    "                if os.path.isfile(file):\n",
    "                    df=pd.read_csv(file,encoding='utf8')\n",
    "                    df['Scenario'] = scenario\n",
    "                    df['Market']   = market\n",
    "                    #Renaming columns just in case timeconversion was required\n",
    "                    df.rename(columns = {'G':'GGG', 'C':'CCC', 'Y':'YYY','TTT_NEW':'TTT','SSS_NEW':'SSS'}, inplace = True) \n",
    "                    data=data.append(df) \n",
    "\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s151529\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#Timestamp addition\n",
    "full_timesteps = pd.read_csv('./input/full_timesteps_'+meaning_SSS_TTT+'.csv')\n",
    "full_timesteps.Key=full_timesteps['SSS']+full_timesteps['TTT']\n",
    "number_periods=len(full_timesteps.Key.unique())\n",
    "full_timesteps['timestamp']= pd.date_range(first_timestep, periods = number_periods, freq =size_timestep)\n",
    "dict_timestamp=dict(zip(full_timesteps.Key, full_timesteps.timestamp))\n",
    "data['timestamp']=data['SSS']+data['TTT']\n",
    "data['timestamp']=data['timestamp'].map(dict_timestamp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional set declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccc = list(data.CCC.unique())\n",
    "rrr = list(data.RRR.unique())\n",
    "#tech_type = list(data.TECH_TYPE.unique())\n",
    "#commodity = list(data.COMMODITY.unique())\n",
    "#fff = list(data.FFF.unique())\n",
    "sss = list(full_timesteps.SSS.unique())\n",
    "ttt = list(full_timesteps.TTT.unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time step selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seasons to investigate\n",
    "# season_names = ['S01', 'S07', 'S20', 'S24', 'S28', 'S38', 'S42', 'S43']\n",
    "# Make a list of every nth element of sss (1 <= nth <= number of elements in sss)\n",
    "nth = 1\n",
    "s = sss[0::nth]\n",
    " # Or select seasons by names\n",
    "# s = season_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Terms to investigate\n",
    "# term_names = ['T005', 'T019', 'T033', 'T047', 'T061', 'T075', 'T089', 'T103', 'T117', 'T131', 'T145', 'T159']\n",
    "# Make a list of every nth element of ttt (1 <= nth <= number of elements in ttt)\n",
    "nth = 1\n",
    "t = ttt[0::nth]\n",
    "# Or select terms by name\n",
    "# t = term_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Directories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make output folder\n",
    "if not os.path.isdir('output'):\n",
    "    os.makedirs('output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make CurtailmentHourly folder\n",
    "if not os.path.isdir('output/' + output):\n",
    "    os.makedirs('output/' + output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make market folder\n",
    "for market in markets:\n",
    "    if not os.path.isdir('output/' + output + '/'+ market +'/Country_wise'):\n",
    "        os.makedirs('output/' + output + '/'+ market +'/Country_wise')\n",
    "# Make country folder\n",
    "    if not os.path.isdir('output/' + output  + '/'+ market +'/Country_wise'):\n",
    "        os.makedirs('output/' + output  + '/'+ market  +'/Country_wise')\n",
    "    # Make country wise folders\n",
    "    for c in ccc:\n",
    "        if not os.path.isdir('output/' + output  + '/'+ market +'/Country_wise/' + c):\n",
    "            os.makedirs('output/' + output  + '/'+ market +'/Country_wise/' + c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make data frames to plot\n",
    "data_plot = data[(data.SSS.isin(s)) & (data.TTT.isin(t))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Data export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.pivot_table(data, values='Val', index=['Market','Scenario','YYY','timestamp'],\n",
    "...                     columns=['RRR'], aggfunc=np.sum, fill_value=0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for market in markets:\n",
    "    for scenario in scenarios:\n",
    "        for year in years:\n",
    "                table_export=table[table.columns.difference(['Market','Scenario','YYY'])].loc[(table['Market'] == market) & (table['Scenario'] == scenario) &  (table['YYY'].astype(str) == year)]\n",
    "                table_export=table_export.set_index(['timestamp'])\n",
    "                table_export.to_csv('Output/'+output+'/'+output+'_'+market+'_'+scenario+'_'+year+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
