{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Imports and inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io, os, sys, types\n",
    "import datetime\n",
    "import glob\n",
    "import gdxpds as gp\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 User inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filetype_input = 'gdx' #Choose input file type: 'gdx' or 'csv'\n",
    "gams_dir = 'C:/GAMS/win64/28.2'\n",
    "markets = ['DayAhead'] #Choose from: 'DayAhead', 'Balancing', 'FullYear', 'Investment'\n",
    "output_name = 'January_test'\n",
    "output_type = ['csv', 'Excel'] #Choose desired output type, from: 'Excel' or 'csv' (or both)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Read which are relevant variables + files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select which variables should be displayed\n",
    "include_file = pd.read_csv('.\\input\\include.csv', encoding='utf8')\n",
    "\n",
    "# drop all variables that shall NOT be included and set the index to the\n",
    "# variable names\n",
    "include_file = include_file[include_file.include == 'YES']\n",
    "del include_file['include']\n",
    "include_file = include_file.set_index('variable')\n",
    "\n",
    "# list of all variable names\n",
    "var_list = list(include_file.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Create column names dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_colnames = pd.read_csv('.\\input\\Dict_column_names.csv')\n",
    "dict_colnames = dict(zip(df_colnames['Old'], df_colnames['New']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Function 1: reading gdx-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_creation(gdx_file, varname):\n",
    "    df = pd.DataFrame()\n",
    "    if '_' in gdx_file:\n",
    "            # if yes: extract scenario name from gdx filename\n",
    "        scenario = gdx_file.split('_', 3)[-3]\n",
    "        year = gdx_file.split('_', 3)[-2]\n",
    "        subset = gdx_file.split('_', 3)[-1][:-4]\n",
    "        market = gdx_file.split('\\\\', 1)[0].split('/',3)[-1]\n",
    "    else:\n",
    "           # if no: use nan instead\n",
    "        scenario = 'nan'\n",
    "\n",
    "    # create empty temporary dataframe and load the gdx data into it\n",
    "    temp = pd.DataFrame()\n",
    "    temp = gp.to_dataframe(gdx_file, varname, gams_dir=gams_dir,\n",
    "                           old_interface=False)\n",
    "\n",
    "    # add a scenario column with the scenario name of the current iteration\n",
    "    temp['Scenario'] = scenario\n",
    "    temp['Market']  = market\n",
    "    temp['run'] = scenario + '_' + year + '_' + subset\n",
    "    \n",
    "    # rearrange the columns' order\n",
    "    cols = list(temp.columns)\n",
    "    cols = [cols[-1]] + cols[:-1]\n",
    "    temp = temp[cols]\n",
    "\n",
    "    # concatenate the temporary dataframe to the preceeding data\n",
    "    df = pd.concat([df, temp], sort=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Use function 1 to read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = list()\n",
    "gdx_file_list = list()\n",
    "\n",
    "# directory to the input gdx file(s)\n",
    "for market in markets:\n",
    "    gdx_file_list = gdx_file_list + glob.glob('./input/results/'+ market + '/*.gdx')\n",
    "\n",
    "all_df = {gdx_file : {varname: df for varname, df in zip(var_list,var_list)} for gdx_file in gdx_file_list}\n",
    "\n",
    "\n",
    "for gdx_file in gdx_file_list:\n",
    "    for varname, df in zip(var_list, var_list):\n",
    "        all_df[gdx_file][varname] = df_creation(gdx_file, varname)\n",
    "        if all_df[gdx_file][varname]['run'][0] not in runs:\n",
    "            runs.append(all_df[gdx_file][varname]['run'][0])\n",
    "            \n",
    "run_dict = dict(zip(gdx_file_list, runs) )\n",
    "all_df = dict((run_dict[key], value) for (key, value) in all_df.items())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Function 2: column aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test function\n",
    "def column_aggregator(input_df, settings):\n",
    "    temp = input_df.copy()\n",
    "    df_cond = settings.copy()\n",
    "    output_df = pd.DataFrame()\n",
    "    \n",
    "    fields_in = list(df_cond['Fields_in'])\n",
    "    fields_in = [x for x in fields_in if str(x) != 'nan']\n",
    "    field_out = df_cond['Field_out'][0]\n",
    "\n",
    "    nan_option = df_cond['nan_option'][0]\n",
    "    nan_output = df_cond['nan_output'][0]\n",
    "\n",
    "    dict_keys = list(df_cond['Keys']) \n",
    "    dict_keys = [x for x in dict_keys if str(x) != 'nan']\n",
    "    \n",
    "    dict_values = list(df_cond['Values'])\n",
    "    dict_values = [x for x in dict_values if str(x) != 'nan']\n",
    "    \n",
    "    dictionary = dict(zip(dict_keys, dict_values))\n",
    "    for i,row in temp.iterrows():\n",
    "        temp.loc[i,'key'] = ''\n",
    "        for field in fields_in:\n",
    "            temp.loc[i,'key'] = temp.loc[i,'key'] + temp.loc[i,field]\n",
    "        if field_out not in list(temp.columns):\n",
    "            temp.loc[i,field_out] = np.NaN\n",
    "            \n",
    "    for j,row in temp.loc[temp['key'].isin(dict_keys), ].iterrows():     \n",
    "        temp.loc[j, field_out] = dictionary[temp.loc[j,'key']]\n",
    "\n",
    "    for k,row in temp.loc[temp[field_out].isna(), ].iterrows():\n",
    "        if nan_option == 'field':\n",
    "            temp.loc[k, field_out] = temp.loc[k, nan_output]\n",
    "        if nan_option == 'string': \n",
    "            temp.loc[k, field_out] = nan_output\n",
    "    output_df = output_df.append(temp)\n",
    "    return output_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Use function 2 to create output dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict={i:pd.DataFrame() for i in var_list}\n",
    "for var in var_list:\n",
    "    if os.path.isfile('.\\input\\settings\\settings_'+ var  +'.xlsx'):\n",
    "        df_settings = pd.read_excel('.\\input\\settings\\settings_'+ var  +'.xlsx', None)\n",
    "    else:\n",
    "        df_settings = pd.DataFrame()\n",
    "        \n",
    "    sheets = list(df_settings.keys())\n",
    "    for run in runs:\n",
    "        temp = all_df[run][var]\n",
    "        for sheet in sheets:\n",
    "            print('working on: ' + var + ', ' + run + ', ' + sheet)\n",
    "            temp = column_aggregator(input_df = temp, settings = df_settings[sheet])\n",
    "        df_dict[var] = df_dict[var].append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Change column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in var_list:\n",
    "    cols = list(df_dict[var].columns)\n",
    "    cols.insert(0,cols[cols.index('Market')])\n",
    "    cols.insert(1,cols[cols.index('Scenario')])\n",
    "    cols.remove('run')\n",
    "    temp = pd.DataFrame()\n",
    "    for i in cols:\n",
    "        temp[i] = df_dict[var][i]\n",
    "    df_dict[var] = temp\n",
    "    df_dict[var] = df_dict[var].rename(columns = dict_colnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Output to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make output folder\n",
    "if not os.path.isdir('output'):\n",
    "    os.makedirs('output')\n",
    "\n",
    "if 'csv' in output_type:\n",
    "    for var in var_list:\n",
    "        df_dict[var].to_csv('./output/' + output_name + '_' + var + '.csv', index = False)\n",
    "             \n",
    "if 'Excel' in output_type:\n",
    "    with pd.ExcelWriter('./output/'+ output_name + '.xlsx') as writer:  \n",
    "        for var in var_list:\n",
    "            df_dict[var].to_excel(writer, sheet_name= var, index = False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
